{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZVKsBxoFvQ6",
        "outputId": "3a05d57c-09e5-418d-fb2d-2003bbc866b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Gf9PuwAHkL0"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/IPL/Final_Experiment2/* /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMzUkK99I0-f"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTcbm6wxI4NP"
      },
      "source": [
        "## Image Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxAhur9J8Uic"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7lDjVhF8XSq",
        "outputId": "62b622a7-a20a-4e5f-b244-b0bd22eb9e5e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
            "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "checkpoint = \"openai/clip-vit-large-patch14\"\n",
        "classifier = pipeline(model=checkpoint, task=\"zero-shot-image-classification\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gHueInJJEYa"
      },
      "outputs": [],
      "source": [
        "def find_label(label):\n",
        "  if label in [\"animal\", \"pet\"]:\n",
        "    return \"animal\", 1\n",
        "  elif label in [\"landscape\", \"city\", \"flower\"]:\n",
        "    return \"landscape\", 2\n",
        "  elif label in [\"sport\"]:\n",
        "    return \"sport\", 3\n",
        "  elif label in [\"chat\", \"book\"]:\n",
        "    return \"text\", 4\n",
        "  elif label in [\"art\", \"painting\", \"statue\"]:\n",
        "    return \"art\", 5\n",
        "  elif label in [\"instrument\"]:\n",
        "    return \"object\", 6\n",
        "  elif label in [\"food\", \"cafe\", \"restaurant\"]:\n",
        "    return \"food\", 7\n",
        "  elif label in [\"people\"]:\n",
        "    return \"people\", 8\n",
        "  elif label in [\"movie\", \"animation\"]:\n",
        "    return \"movie\", 9\n",
        "  elif label in [\"music\"]:\n",
        "    return \"music\", 10\n",
        "  elif label in [\"shop\"]:\n",
        "    return \"shop\", 11\n",
        "  return \"other\", 12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F33Gk4oJJgC"
      },
      "source": [
        "## Face Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SmAbtor8Hzw"
      },
      "outputs": [],
      "source": [
        "!pip3 install face_recognition\n",
        "!git clone https://github.com/davisking/dlib.git\n",
        "%cd dlib\n",
        "!pip install cmake\n",
        "!mkdir build\n",
        "%cd build\n",
        "!cmake ..; cmake --build .\n",
        "%cd ..\n",
        "!python3 setup.py install\n",
        "%cd ..\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RcFga019K38"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import face_recognition\n",
        "\n",
        "def face_detection(profile, media_pic, media_id, id, mediaset):\n",
        "  # print(media_pic)\n",
        "  picture_of_me = face_recognition.load_image_file(profile)\n",
        "  my_face_encoding = face_recognition.face_encodings(picture_of_me)[0]\n",
        "  unknown_picture = face_recognition.load_image_file(media_pic)\n",
        "  # unknown_face_encoding = face_recognition.face_encodings(unknown_picture)[0]\n",
        "  # results = face_recognition.compare_faces([my_face_encoding], unknown_face_encoding)\n",
        "\n",
        "  face_locations = face_recognition.face_locations(unknown_picture)\n",
        "  image = unknown_picture\n",
        "  # print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
        "\n",
        "  for face_location in face_locations:\n",
        "\n",
        "      # Print the location of each face in this image\n",
        "      top, right, bottom, left = face_location\n",
        "      # print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
        "\n",
        "      # You can access the actual face itself like this:\n",
        "      face_image = image[top:bottom, left:right]\n",
        "      pil_image = Image.fromarray(face_image)\n",
        "      _ = pil_image.save(f'{id}/media/media{id}-{media_id}.jpg')\n",
        "      face = face_recognition.load_image_file(f'{id}/media/media{id}-{media_id}.jpg')\n",
        "      if len(face_recognition.face_encodings(face)) == 0:\n",
        "        os.remove(f'{id}/media/media{id}-{media_id}.jpg')\n",
        "        continue\n",
        "      else:\n",
        "        mediaset.add(media_pic)\n",
        "      face = face_recognition.face_encodings(face)[0]\n",
        "      # print(\"face_recognition.compare_faces([my_face_encoding], face)\", face_recognition.compare_faces([my_face_encoding], face))\n",
        "      if not face_recognition.compare_faces([my_face_encoding], face)[0]:\n",
        "        os.remove(f'{id}/media/media{id}-{media_id}.jpg')\n",
        "      else:\n",
        "        mediaset.add(media_pic)\n",
        "        # print(\"yes\")\n",
        "      pil_image = Image.fromarray(face_image)\n",
        "      pil_image.show()\n",
        "      media_id += 1\n",
        "  return media_id, mediaset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEW7yXscLIaT"
      },
      "source": [
        "## Facial Expression Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lCGuyF2R415"
      },
      "outputs": [],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSMKlWxMR97Z"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "\n",
        "# model_reloaded = timm.create_model('schibsted/Facial_Recognition_with_Sentiment_Detector', pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rv8BDwIiSB77"
      },
      "outputs": [],
      "source": [
        "# Facial expression classifier\n",
        "import os\n",
        "from fastai.vision.all import *\n",
        "\n",
        "# Emotion\n",
        "learn_emotion = load_learner('emotions_vgg19.pkl')\n",
        "learn_emotion_labels = learn_emotion.dls.vocab\n",
        "\n",
        "# Sentiment\n",
        "# learn_sentiment = load_learner('sentiment_vgg19.pkl')\n",
        "# learn_sentiment_labels = learn_sentiment.dls.vocab\n",
        "\n",
        "# Predict\n",
        "def predict(img):\n",
        "    img = PILImage.create(img)\n",
        "\n",
        "    pred_emotion, pred_emotion_idx, probs_emotion = learn_emotion.predict(img)\n",
        "\n",
        "    # pred_sentiment, pred_sentiment_idx, probs_sentiment = learn_sentiment.predict(img)\n",
        "\n",
        "    #emotions = {f'emotion_{learn_emotion_labels[i]}': float(probs_emotion[i]) for i in range(len(learn_emotion_labels))}\n",
        "    #sentiments = {f'sentiment_{learn_sentiment_labels[i]}': float(probs_sentiment[i]) for i in range(len(learn_sentiment_labels))}\n",
        "\n",
        "    emotions = {learn_emotion_labels[i]: float(probs_emotion[i]) for i in range(len(learn_emotion_labels))}\n",
        "    # sentiments = {learn_sentiment_labels[i]: float(probs_sentiment[i]) for i in range(len(learn_sentiment_labels))}\n",
        "\n",
        "    return [emotions] #{**emotions, **sentiments}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QiVLY038SAm"
      },
      "source": [
        "# Image Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfiLVntl8aME"
      },
      "outputs": [],
      "source": [
        "def image_classification(id, files_list):\n",
        "  ic = \"\"\n",
        "  for i in range(len(files_list)):\n",
        "    image = Image.open(f'{id}/{files_list[i]}')\n",
        "    predictions = classifier(image, candidate_labels=[\"animal\", \"pet\", \"landscape\", \"sport\", \"chat\", \"art\", \"instrument\", \"food\", \"people\", \"movie\", \"music\", \"shop\", \"cafe\", \"restaurant\", \"city\", \"painting\", \"statue\", \"book\", \"animation\", \"flower\"])\n",
        "    print(find_label(predictions[0]['label'])[1], end=\"#\")\n",
        "    ic += str(find_label(predictions[0]['label'])[1])\n",
        "    ic += \"#\"\n",
        "  print()\n",
        "  return ic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqYer4Ad8Iqc"
      },
      "source": [
        "# Face Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2r0l7FHS9zFH"
      },
      "outputs": [],
      "source": [
        "def face_recognition_module(id, files_list):\n",
        "  media_id = 0\n",
        "  mediaset = set()\n",
        "  if os.path.isdir(f\"{id}/media\"):\n",
        "    shutil.rmtree(f\"{id}/media\")\n",
        "  os.mkdir(f\"{id}/media\")\n",
        "  for i in files_list:\n",
        "    if i != \"profile.jpeg\":\n",
        "      media_id, mediaset = face_detection(f\"{id}/profile.jpeg\", f\"{id}/{i}\", media_id, id, mediaset)\n",
        "\n",
        "  media_list = [f for f in listdir(join(id, \"media\")) if isfile(join(join(id, \"media\"), f))]\n",
        "  print(mediaset)\n",
        "  print(len(media_list)/(len(files_list)-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYT8b2vQR247"
      },
      "source": [
        "# Facial Expression Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xVSCW9pLy9Y"
      },
      "outputs": [],
      "source": [
        "def facial_expression_analysis(id):\n",
        "  expressions = predict(f\"{id}/profile.jpeg\")[0]\n",
        "  expressions[\"angry\"] *= 3\n",
        "  expressions[\"disgust\"] *= 3\n",
        "  expressions[\"fear\"] *= 3\n",
        "  expressions[\"happy\"] *= 3\n",
        "  expressions[\"neutral\"] *= 3\n",
        "  expressions[\"sad\"] *= 3\n",
        "  expressions[\"surprise\"] *= 3\n",
        "  media_list = [f for f in listdir(join(id, \"media\")) if isfile(join(join(id, \"media\"), f))]\n",
        "  for i in media_list:\n",
        "    exp = predict(f\"{id}/media/{i}\")[0]\n",
        "    expressions[\"angry\"] += exp[\"angry\"]\n",
        "    expressions[\"disgust\"] += exp[\"disgust\"]\n",
        "    expressions[\"fear\"] += exp[\"fear\"]\n",
        "    expressions[\"happy\"] += exp[\"happy\"]\n",
        "    expressions[\"neutral\"] += exp[\"neutral\"]\n",
        "    expressions[\"sad\"] += exp[\"sad\"]\n",
        "    expressions[\"surprise\"] += exp[\"surprise\"]\n",
        "\n",
        "  expressions[\"angry\"] /= (len(media_list)+3)\n",
        "  expressions[\"disgust\"] /= (len(media_list)+3)\n",
        "  expressions[\"fear\"] /= (len(media_list)+3)\n",
        "  expressions[\"happy\"] /= (len(media_list)+3)\n",
        "  expressions[\"neutral\"] /= (len(media_list)+3)\n",
        "  expressions[\"sad\"] /= (len(media_list)+3)\n",
        "  expressions[\"surprise\"] /= (len(media_list)+3)\n",
        "  print(expressions)\n",
        "  return expressions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tqt5vG1CMBBV"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuSTgdCHls8Z"
      },
      "outputs": [],
      "source": [
        "# topics = \"6#9#9#9#9#9#9#9#9#9#9#9#9#9#9#9#9#9#9#9\"\n",
        "\n",
        "def format_topics(topics):\n",
        "  reshte = topics.split(\"#\")\n",
        "  reshte.pop()\n",
        "  print(reshte)\n",
        "\n",
        "  def labels(label):\n",
        "    if label == \"animal\":\n",
        "      return 1\n",
        "    elif label == \"landscape\":\n",
        "      return 2\n",
        "    elif label == \"sport\":\n",
        "      return 3\n",
        "    elif label == \"text\":\n",
        "      return 4\n",
        "    elif label == \"art\":\n",
        "      return 5\n",
        "    elif label == \"object\":\n",
        "      return 6\n",
        "    elif label == \"food\":\n",
        "      return 7\n",
        "    elif label == \"people\":\n",
        "      return 8\n",
        "    elif label == \"movie\":\n",
        "      return 9\n",
        "    elif label == \"music\":\n",
        "      return 10\n",
        "    elif label == \"shop\":\n",
        "      return 11\n",
        "    return 12\n",
        "\n",
        "  results = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "  count_reshte = 0\n",
        "  for i in reshte:\n",
        "    # if i == '':\n",
        "    #   continue\n",
        "    count_reshte += 1\n",
        "    results[int(i)-1] += 1\n",
        "\n",
        "\n",
        "  for r in range(len(results)):\n",
        "    results[r] /= count_reshte\n",
        "    results[r] *= 100\n",
        "    results[r] = str(int(results[r]))\n",
        "\n",
        "  return \"#\".join(results)\n",
        "\n",
        "# print(format_topics(topics))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySwt1gBtm8wQ"
      },
      "outputs": [],
      "source": [
        "# sentiment = {'angry': 0.015877289033142006, 'disgust': 0.012511020366478729, 'fear': 0.14441619933183705, 'happy': 0.27127157151699066, 'neutral': 0.11558954133570533, 'sad': 0.02055548384226848, 'surprise': 0.4197788978261607}\n",
        "\n",
        "def format_sentiment(sentiment):\n",
        "  sent = \"\"\n",
        "  sent += (str(round(sentiment[\"happy\"], 4)) + \"#\")\n",
        "  sent += (str(round(sentiment[\"sad\"], 4)+round(sentiment[\"fear\"], 4)) + \"#\")\n",
        "  sent += (str(round(sentiment[\"angry\"], 4)+round(sentiment[\"disgust\"], 4)) + \"#\")\n",
        "  sent += (str(round(sentiment[\"neutral\"], 4)) + \"#\")\n",
        "  sent += str(round(sentiment[\"surprise\"], 4))\n",
        "  return sent\n",
        "\n",
        "# print(format_sentiment(sentiment))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9wmoVOgnmfq"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "ids_lst = [\n",
        "# \"supsnm\",\n",
        "# \"mmsamiei97\",\n",
        "# \"sarative\",\n",
        "# \"Masihbr\",\n",
        "# \"SElahimanesh\",\n",
        "# \"mohammadali_79\",\n",
        "# \"iTs_kAsraa\",\n",
        "# \"alizademhdi\",\n",
        "# \"majidtaherkhan5\",\n",
        "# \"Iman_M_02\",\n",
        "# \"MojoodeZende\",\n",
        "# \"lellahka\",\n",
        "# \"Donya_rz\",\n",
        "# \"RFzarghani\",\n",
        "# \"Kahbye\",\n",
        "# \"amirhbrt\",\n",
        "# \"Thy_Crow\",\n",
        "# \"lonelyrtalking\",\n",
        "# \"itszahraaw\",\n",
        "# \"alilordloss\",\n",
        "# \"pahdemy\",\n",
        "# \"arearevalla\",\n",
        "# \"the_shabe\",\n",
        "# \"A_zoje\",\n",
        "# \"Amirzgh1\",\n",
        "# \"GhermezzzMohi\",\n",
        "# \"Zhra_arj\",\n",
        "# \"SuccessfulEhsan\",\n",
        "# \"Aelirus\",\n",
        "# \"Sqrtpiee\",\n",
        "# \"WhatYouSeeIsMee\",\n",
        "# \"aexomir1\",\n",
        "# \"Esmailysetayesh\",\n",
        "# \"Shepelll\",\n",
        "# \"nottheoneuknow_\",\n",
        "# \"Haamedht\",\n",
        "# \"ItisHoor\",\n",
        "# \"Necessiite\",\n",
        "# \"BirdSuspicious\",\n",
        "# \"Yganeyzdi\",\n",
        "# \"MguidedS\",\n",
        "# \"Atenanourii\",\n",
        "# \"Ehsanino82\",\n",
        "# \"___mamali___\",\n",
        "# \"MGhasemi8156\",\n",
        "# \"BardiaWasHere\",\n",
        "# \"seginus14\",\n",
        "# \"Smmhatami\",\n",
        "# \"OneToBeShunned\",\n",
        "# \"Hamriouz\",\n",
        "# \"amirhossein_nr\",\n",
        "# \"maghasemzadeh\",\n",
        "# \"MehradMilan\",\n",
        "# \"hosseinkhaniii\",\n",
        "# \"AmirrezaFN2000\",\n",
        "# \"BardiaT3\",\n",
        "# \"aminam80\",\n",
        "# \"Mr_mahdimirzaei\",\n",
        "# \"FatemehAsgarii\",\n",
        "# \"rez1pm\",\n",
        "# \"mahdiakhi\",\n",
        "# \"Zhugulibu\",\n",
        "# \"SMahdiFaghih\",\n",
        "# \"its_Hedy\",\n",
        "# \"Thebigwhoman\",\n",
        "# \"atalmataltotol\"\n",
        "# \"ReallyNemidanam\",\n",
        "# \"GhermezzzMohi\"\n",
        "# \"aidinhnkhn\",\n",
        "# \"imligeia\",\n",
        "# \"Aliredaq\",\n",
        "# \"cabrrrrrrron\",\n",
        "# \"sharif0108\",\n",
        "# \"slmktbr\"\n",
        "\"pouyalahabi\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfylwJoSMIjG"
      },
      "outputs": [],
      "source": [
        "def run_test(id):\n",
        "  files_list = [f for f in listdir(id) if isfile(join(id, f))]\n",
        "  ##\n",
        "  lst = []\n",
        "  for i in files_list:\n",
        "    if i.replace(\".jpeg\", \"\").isdigit():\n",
        "      lst.append(int(i.replace(\".jpeg\", \"\")))\n",
        "  lst.sort()\n",
        "  files_list = []\n",
        "  for i in lst:\n",
        "    files_list.append(f\"{i}.jpeg\")\n",
        "  ##\n",
        "  print(id, len(files_list), files_list)\n",
        "  # print(files_list)\n",
        "  print(\"TOPICS\", format_topics(image_classification(id, files_list)))\n",
        "  try:\n",
        "    face_recognition_module(id, files_list)\n",
        "  except:\n",
        "    print(\"face_recognition not possible!\")\n",
        "  print(\"EXPRESSIONS\", format_sentiment(facial_expression_analysis(id)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "tbw-qpjMMeW8",
        "outputId": "0f5334c5-2cfe-4b5c-8c48-bf3357c0ce6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pouyalahabi 20 ['1.jpeg', '2.jpeg', '3.jpeg', '4.jpeg', '5.jpeg', '6.jpeg', '7.jpeg', '8.jpeg', '9.jpeg', '10.jpeg', '11.jpeg', '12.jpeg', '13.jpeg', '14.jpeg', '15.jpeg', '16.jpeg', '17.jpeg', '18.jpeg', '19.jpeg', '20.jpeg']\n",
            "8#9#4#9#9#9#4#4#4#2#8#8#8#8#2#1#5#8#8#8#\n",
            "['8', '9', '4', '9', '9', '9', '4', '4', '4', '2', '8', '8', '8', '8', '2', '1', '5', '8', '8', '8']\n",
            "TOPICS 5#10#0#20#5#0#0#40#20#0#0\n",
            "{'pouyalahabi/11.jpeg', 'pouyalahabi/14.jpeg', 'pouyalahabi/13.jpeg', 'pouyalahabi/17.jpeg', 'pouyalahabi/3.jpeg', 'pouyalahabi/18.jpeg', 'pouyalahabi/20.jpeg'}\n",
            "0.3157894736842105\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'angry': 0.10982356367296436, 'disgust': 0.02201911976347522, 'fear': 0.03574925469648507, 'happy': 0.3578552446431584, 'neutral': 0.1172441607842403, 'sad': 0.06436336646179876, 'surprise': 0.2929453342739079}\n",
            "EXPRESSIONS 0.3579#0.1001#0.1318#0.1172#0.2929\n"
          ]
        }
      ],
      "source": [
        "for i in ids_lst:\n",
        "  run_test(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDSFr5ILT5qo"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "D8Q01CYXUBf7",
        "outputId": "1e835850-0ba8-49ee-ad0e-69a4b7cd6c1d"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-052dc1a09203>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mdeghat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'labels.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mspamreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'|'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspamreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'labels.csv'"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "topics = \"6#9#9#9#9#9#9#9#9#9#9#9#9#9#9#9#9#9#9#9\"\n",
        "reshte = topics.split(\"#\")\n",
        "id = \"mr_hooomed\"\n",
        "\n",
        "def labels(label):\n",
        "  if label == \"animal\":\n",
        "    return 1\n",
        "  elif label == \"landscape\":\n",
        "    return 2\n",
        "  elif label == \"sport\":\n",
        "    return 3\n",
        "  elif label == \"text\":\n",
        "    return 4\n",
        "  elif label == \"art\":\n",
        "    return 5\n",
        "  elif label == \"object\":\n",
        "    return 6\n",
        "  elif label == \"food\":\n",
        "    return 7\n",
        "  elif label == \"people\":\n",
        "    return 8\n",
        "  elif label == \"movie\":\n",
        "    return 9\n",
        "  elif label == \"music\":\n",
        "    return 10\n",
        "  elif label == \"shop\":\n",
        "    return 11\n",
        "  return 12\n",
        "\n",
        "this_id = id\n",
        "flag = 0\n",
        "deghat = 0\n",
        "counter = -2\n",
        "with open('labels.csv', newline='') as csvfile:\n",
        "    spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
        "    for row in spamreader:\n",
        "      if \",media\" in row:\n",
        "        break\n",
        "      if row[0].split(\",\")[0] == this_id:\n",
        "        counter += 1\n",
        "        if flag == 0:\n",
        "          flag = 1\n",
        "          continue\n",
        "        # print(row[0].split(\",\")[4].split(\"/\"), counter)\n",
        "        for i in row[0].split(\",\")[4].split(\"/\"):\n",
        "          # print(reshte[counter], labels(i))\n",
        "          if int(reshte[counter]) == labels(i):\n",
        "            # print(deghat)\n",
        "            deghat += 1\n",
        "# print(len(reshte))\n",
        "print(deghat/len(reshte))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfegjRZ0hsQC"
      },
      "outputs": [],
      "source": [
        "id = \"SElahimanesh\"\n",
        "topics = \"7#7#8#11#2#4#4#2#4#4#4#4#4#2#1#11#4#11#4#8\"\n",
        "\n",
        "files_list = [f for f in listdir(id) if isfile(join(id, f))]\n",
        "lst = []\n",
        "for i in files_list:\n",
        "  if i.replace(\".jpeg\", \"\").isdigit():\n",
        "    lst.append(int(i.replace(\".jpeg\", \"\")))\n",
        "lst.sort()\n",
        "files_list = []\n",
        "for i in lst:\n",
        "  files_list.append(f\"{i}.jpeg\")\n",
        "print(id, files_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5F_0gnh5QsE"
      },
      "source": [
        "# Earth Mover's Distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8Ckynqw5TuH",
        "outputId": "b24d0680-347e-42b0-9908-db6ecc38b930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity 0.8397441023590564\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "def earth_movers_distance(p, q):\n",
        "    if len(p) != len(q):\n",
        "        raise ValueError(\"Input sets must have the same length.\")\n",
        "\n",
        "    # Normalize the input sets to ensure they sum to 1\n",
        "    p = np.array(p) / np.sum(p)\n",
        "    q = np.array(q) / np.sum(q)\n",
        "\n",
        "    # Calculate the cost matrix\n",
        "    cost_matrix = np.abs(np.subtract.outer(p, q))\n",
        "\n",
        "    # Solve the linear sum assignment problem to find optimal transport plan\n",
        "    row_indices, col_indices = linear_sum_assignment(cost_matrix)\n",
        "\n",
        "    # Calculate the Earth Mover's Distance\n",
        "    emd = cost_matrix[row_indices, col_indices].sum()\n",
        "\n",
        "    return emd\n",
        "\n",
        "# Example usage:\n",
        "set1 = [42.34, 2.7, 0, 46.85, 7.21]\n",
        "set2 = [45.9, 8.66, 4.88, 4.48, 36.12]\n",
        "\n",
        "distance = earth_movers_distance(set1, set2)\n",
        "print(\"Similarity\", 1-distance)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL6oQBWicYAw"
      },
      "source": [
        "# KL Divergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGthAtqJcamo"
      },
      "outputs": [],
      "source": [
        "#define two probability distributions\n",
        "P = [0.1, 0.15, 0.25, 0.3, 0.2]\n",
        "Q = [0.2, 0.3, 0.25, 0.15, 0.1]\n",
        "from scipy.special import rel_entr\n",
        "\n",
        "#calculate (P || Q)\n",
        "sum(rel_entr(P, Q))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO9zeMUEdVDC"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "sklearn.metrics.mutual_info_score(P, Q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzQSzsxrd0n5"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "# calculate the kl divergence\n",
        "def kl_divergence(p, q):\n",
        " return sum(p[i] * math.log((p[i]/q[i]), 2) for i in range(len(p)))\n",
        "\n",
        "kl_divergence(P, Q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hfr_gl9x206Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "921416e6-3f04-4d45-d492-77d9ae62c981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jensen-Shannon Divergence Similarity: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-a52dde4de1fc>:15: RuntimeWarning: divide by zero encountered in log2\n",
            "  kl_divergence_p = np.sum(p * np.log2(p / m))\n",
            "<ipython-input-1-a52dde4de1fc>:15: RuntimeWarning: invalid value encountered in multiply\n",
            "  kl_divergence_p = np.sum(p * np.log2(p / m))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def jensen_shannon_divergence(p, q):\n",
        "    if len(p) != len(q):\n",
        "        raise ValueError(\"Input sets must have the same length.\")\n",
        "\n",
        "    # Normalize the input sets to ensure they sum to 1\n",
        "    p = np.array(p) / np.sum(p)\n",
        "    q = np.array(q) / np.sum(q)\n",
        "\n",
        "    # Calculate the midpoint distribution\n",
        "    m = 0.5 * (p + q)\n",
        "\n",
        "    # Calculate the KL divergences from p and q to m\n",
        "    kl_divergence_p = np.sum(p * np.log2(p / m))\n",
        "    kl_divergence_q = np.sum(q * np.log2(q / m))\n",
        "\n",
        "    # Calculate the average of the KL divergences (Jensen-Shannon Divergence)\n",
        "    jensen_shannon_divergence = 0.5 * (kl_divergence_p + kl_divergence_q)\n",
        "\n",
        "    return jensen_shannon_divergence\n",
        "\n",
        "# Example usage:\n",
        "set1 = [42.34, 2.7, 0, 46.85, 0]\n",
        "set2 = [45.9, 8.66, 4.88, 4.48, 36.12]\n",
        "\n",
        "distance = jensen_shannon_divergence(set1, set2)\n",
        "print(\"Jensen-Shannon Divergence Similarity:\", 1- distance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzlbdWMl40Gt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def euclidean_distance(p, q):\n",
        "    if len(p) != len(q):\n",
        "        raise ValueError(\"Input sets must have the same length.\")\n",
        "\n",
        "    p = np.array(p)\n",
        "    q = np.array(q)\n",
        "\n",
        "    # Calculate the Euclidean distance\n",
        "    euclidean_distance = np.sqrt(np.sum((p - q)**2))\n",
        "\n",
        "    return euclidean_distance\n",
        "\n",
        "# Example usage:\n",
        "set1 = [0.1, 0.1, 0.1, 0.1, 0.6]\n",
        "set2 = [0.15, 0.25, 0.25, 0.2, 0.15]\n",
        "\n",
        "distance = euclidean_distance(set1, set2)\n",
        "print(\"Euclidean Distance:\", 1-distance)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HutzxlXqESYj"
      },
      "source": [
        "# Extra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vE7TEQ5s9KSF"
      },
      "outputs": [],
      "source": [
        "# !mv images/images/* ./\n",
        "!rm -r \"images\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dsMbR6s9Q0T"
      },
      "outputs": [],
      "source": [
        "for i in ids_lst:\n",
        "  if not os.path.exists(i):\n",
        "    !mkdir {i}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFEo4MGlbxId"
      },
      "outputs": [],
      "source": [
        "!jar xvf \"images.zip\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "HutzxlXqESYj"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}